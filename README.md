# WorldWithoutDarkness
This code assists visually impaired individuals by providing image question answering capabilities. It utilizes a multimodal AI model, a speech-to-text model, and a text-to-speech engine. 
Here's how it works:
The user activates the microphone using a push button and records their speech. If the user says "Take a photo," the solution captures an image using a USB camera. Otherwise, it uses the last captured image       and the recorded speech.
The image and speech are then sent to the multimodal AI model. This model processes the visual data, extracting information about objects, scenes, and environments. It also analyzes the speech to understand       the user's question.
The processed information is then converted into a comprehensive and detailed answer to the user's question. This answer is passed to the text-to-speech engine, which converts it into an audio output.The audio output is played back to the user, providing them with the requested information. The solution then waits for another activation, ready to assist with the next query or command.
By combining computer vision, speech recognition, and natural language processing technologies, this solution empowers visually impaired individuals to understand their surroundings and obtain relevant information through a simple and accessible interface.
